{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc67b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 1/5: \n",
      "\tLoss sul train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:07<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 27.4467\n",
      "\tLoss sul Valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 5.5680\n",
      "\tEvaluation sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.14160335063934326\n",
      "\n",
      "\n",
      "Epoca 2/5: \n",
      "\tLoss sul train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 18.2498\n",
      "\tLoss sul Valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 5.3972\n",
      "\tEvaluation sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.1504795104265213\n",
      "\n",
      "\n",
      "Epoca 3/5: \n",
      "\tLoss sul train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 13.3489\n",
      "\tLoss sul Valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 5.0015\n",
      "\tEvaluation sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.2777068018913269\n",
      "\n",
      "\n",
      "Epoca 4/5: \n",
      "\tLoss sul train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 10.9920\n",
      "\tLoss sul Valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 5.0327\n",
      "\tEvaluation sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.27469402551651\n",
      "\n",
      "\n",
      "Epoca 5/5: \n",
      "\tLoss sul train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 10.0288\n",
      "\tLoss sul Valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-Score: 4.8775\n",
      "\tEvaluation sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.2904372811317444\n",
      "\n",
      "\n",
      "Training complete. Model saved.\n",
      "Score sul test set:\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmap_50: 0.4308501183986664\n",
      "saved prediction to: prova5/predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\utils.py:211: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, root, image_set=\"train\"):\n",
    "        self.root = root\n",
    "        self.transforms = T.Compose([\n",
    "                                T.ToTensor()                         \n",
    "                            ])\n",
    "        image_set_file = os.path.join(root, \"ImageSets\", \"Main\", f\"{image_set}.txt\")\n",
    "        with open(image_set_file) as f:\n",
    "            self.image_ids = [x.strip() for x in f.readlines()]\n",
    "        self.img_dir = os.path.join(root, \"JPEGImages\")\n",
    "        self.ann_dir = os.path.join(root, \"Annotations\")\n",
    "        self.classes = [\"__background__\"] + self._find_classes()\n",
    "        self.image_files = sorted([f for f in os.listdir(self.img_dir) if f.endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    def _find_classes(self):\n",
    "        cls = set()\n",
    "        for fname in os.listdir(self.ann_dir):\n",
    "            tree = ET.parse(os.path.join(self.ann_dir, fname))\n",
    "            for obj in tree.findall(\"object\"):\n",
    "                cls.add(obj.find(\"name\").text)\n",
    "        return sorted(list(cls))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{image_id}.jpg\")\n",
    "        ann_path = os.path.join(self.ann_dir, f\"{image_id}.xml\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes, labels = [], []\n",
    "        for obj in root.findall(\"object\"):\n",
    "            label = obj.find(\"name\").text\n",
    "            labels.append(self.classes.index(label))\n",
    "\n",
    "            bndbox = obj.find(\"bndbox\")\n",
    "            bbox = [\n",
    "                float(bndbox.find(\"xmin\").text),\n",
    "                float(bndbox.find(\"ymin\").text),\n",
    "                float(bndbox.find(\"xmax\").text),\n",
    "                float(bndbox.find(\"ymax\").text),\n",
    "            ]\n",
    "            boxes.append(bbox)\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            # ðŸ” Prova a caricare un'altra immagine se questa Ã¨ vuota\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "            \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "\n",
    "def get_model(num_classes,imgsz):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,min_size=imgsz,max_size=imgsz) #scaling, CosÃ¬ lascia che sia il backbone stesso a ridimensionare correttamente l'immagine e i box interni, preservando la compatibilitÃ . \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def evaluate_metrics(experiment_name,model, data_loader, device,epoch,set):\n",
    "    csv_path = f\"{experiment_name}/{set}_metrics.csv\"\n",
    "    mAP50 = 0.0\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision()\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"\\t\\tEvaluating\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "            metric.update(outputs, targets)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    results = metric.compute()\n",
    "\n",
    "    # Print\n",
    "    \n",
    "    for k, v in results.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            if(k==\"map_50\"):\n",
    "                print(f\"\\t\\t{k}: {v.item() if v.numel() == 1 else v}\")\n",
    "                mAP50 = v.item()\n",
    "    metric.reset()\n",
    "    # Save to CSV\n",
    "    summary = {k: v.item() if isinstance(v, torch.Tensor) and v.numel() == 1 else str(v)\n",
    "               for k, v in results.items()}\n",
    "    #summary[\"epoch\"] = epoch\n",
    "\n",
    "    if (epoch is not None): summary = dict([(\"epoch\", epoch)] + list(summary.items()))\n",
    "\n",
    "    df = pd.DataFrame([summary])\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', header=write_header, index=False)\n",
    "    #print(f\"\\nSaved metrics to: {csv_path}\")\n",
    "    return mAP50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import random\n",
    "\n",
    "def show_predictions(experiment_name,model, dataset, device, score_threshold=0.25,class_names=[]):\n",
    "    model.eval()\n",
    "    output_dir=f\"{experiment_name}/predictions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, target = dataset[idx]\n",
    "        img_tensor = img.to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)[0]\n",
    "\n",
    "        # Filtro predizioni con punteggio basso\n",
    "        keep = output['scores'] >= score_threshold\n",
    "        pred_boxes = output['boxes'][keep].cpu()\n",
    "        pred_labels = output['labels'][keep].cpu()\n",
    "        scores = output['scores'][keep].cpu()\n",
    "\n",
    "        # Disegna box predetti\n",
    "        pred_img = draw_bounding_boxes((img * 255).byte(), pred_boxes, labels=[f\"{class_names[l.item()]}: {s.item():.2f}\" for l,s in zip(pred_labels,scores)],\n",
    "                                       colors=[\"#{:06x}\".format(random.randint(0, 0xFFFFFF)) for l in pred_labels], width=2,font_size=20,font=\"arial\")\n",
    "\n",
    "        # Disegna box reali\n",
    "        # true_boxes = target['boxes'].cpu()\n",
    "        # true_labels = target['labels'].cpu()\n",
    "        # full_img = draw_bounding_boxes(pred_img, true_boxes, labels=[f\"T:{l.item()}\" for l in true_labels],\n",
    "        #                                colors=\"green\", width=2)\n",
    "\n",
    "        \n",
    "\n",
    "        # Nome originale immagine\n",
    "        original_filename = dataset.image_files[idx] # Es: \"img001.jpg\"\n",
    "        output_filename = os.path.splitext(original_filename)[0] + \"_pred.jpg\"\n",
    "\n",
    "        # Salva immagine\n",
    "        img_pil = to_pil_image(pred_img)\n",
    "        img_pil.save(os.path.join(output_dir, output_filename))\n",
    "        \n",
    "    print(f\"saved prediction to: {output_dir}\")\n",
    "\n",
    "def load_custom_fasterrcnn_model(model_path, num_classes,imgsz):\n",
    "    \"\"\"\n",
    "    Carica un modello Faster R-CNN ResNet50 addestrato per un task personalizzato,\n",
    "    usando i pesi salvati con `state_dict`.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Percorso del file .pth contenente lo state_dict salvato.\n",
    "        num_classes (int): Numero totale di classi (incluso lo sfondo).\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: Modello caricato e spostato su GPU (se disponibile).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Carica il modello base\n",
    "    model = get_model(num_classes=num_classes,imgsz=imgsz)\n",
    "\n",
    "    # Carica i pesi salvati\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device,weights_only=True))\n",
    "\n",
    "    # Sposta il modello sul dispositivo corretto\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def FRCNN_train(experiment_name,dataset_path,batch_size=1,imgsz=416):\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    save_weights_dir = f\"{experiment_name}/weights\"\n",
    "    num_epochs = 5\n",
    "    writer = SummaryWriter(f\"logs/faster_rcnn50/{experiment_name}\")\n",
    "\n",
    "    # Imposta la risoluzione desiderata \n",
    "    #desired_size = (imgsz, imgsz)  \n",
    "    transforms = T.Compose([\n",
    "        #T.Resize(desired_size),              #sbagliata perchÃ¨ fare il resize per ogni immagine lascia la size dei BB originale e sballa loss e metriche \n",
    "        T.ToTensor()                         \n",
    "    ])\n",
    "    \n",
    "    \n",
    "\n",
    "    dataset_train = VOCDataset(dataset_path, image_set=\"train\")\n",
    "    dataset_valid = VOCDataset(dataset_path, image_set=\"val\")\n",
    "    dataset_test = VOCDataset(dataset_path, image_set=\"test\")\n",
    "    data_loader_train = DataLoader(dataset_train, batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    data_loader_valid = DataLoader(dataset_valid, batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "    model = get_model(num_classes=len(dataset_train.classes),imgsz=imgsz)\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_score_valid = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_loss_valid = 0.0\n",
    "        print(f\"Epoca {epoch+1}/{num_epochs}: \\n\\tLoss sul train set:\")\n",
    "        for images, targets in tqdm(data_loader_train, desc=f\"\\t\\t\"):\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            total_loss += losses.item()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        print(f\"\\t\\t-Score: {total_loss:.4f}\")\n",
    "        print(f\"\\tLoss sul Valid set:\")\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for images, targets in tqdm(data_loader_valid, desc=f\"\\t\\t\"):\n",
    "                images = list(img.to(device) for img in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                \n",
    "                total_loss_valid += losses.item()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "        print(f\"\\t\\t-Score: {total_loss_valid:.4f}\")    \n",
    "        writer.add_scalar(\"loss/train\", total_loss, epoch+1)\n",
    "        writer.add_scalar(\"loss/valid\", total_loss_valid, epoch+1)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        model.eval()  #Entra in modalitaÌ€ evaluation\n",
    "        #EVALUATION PER EPOCA SUL VALID SET\n",
    "        print(\"\\tEvaluation sul valid set:\")\n",
    "        current_score_valid = evaluate_metrics(experiment_name=experiment_name,model=model, data_loader=data_loader_valid, device=device, epoch=epoch+1,set=\"valid\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        os.makedirs(save_weights_dir, exist_ok=True)\n",
    "        \n",
    "        if current_score_valid > best_score_valid:\n",
    "            best_score_valid = current_score_valid\n",
    "            torch.save(model.state_dict(), f\"{save_weights_dir}/fasterrcnn_voc_best.pth\")\n",
    "            \n",
    "\n",
    "        torch.save(model.state_dict(), f\"{save_weights_dir}/fasterrcnn_voc_last.pth\")\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "    print(\"Training complete. Model saved.\")\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "def FRCNN_eval(experiment_name,model,dataset_path,batch_size=1,imgsz=416):\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    dataset_train = VOCDataset(dataset_path, image_set=\"train\")\n",
    "    dataset_test = VOCDataset(dataset_path, image_set=\"test\")\n",
    "    data_loader_test = DataLoader(dataset_test, batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    #EVALUATION SUL TEST SET CON IL BEST MODEL\n",
    "\n",
    "    model =  load_custom_fasterrcnn_model(model_path=f\"{experiment_name}/weights/fasterrcnn_voc_best.pth\", num_classes=len(dataset_train.classes),imgsz=imgsz)\n",
    "    print(\"Score sul test set:\\t\")\n",
    "\n",
    "    evaluate_metrics(experiment_name=experiment_name,model=model, data_loader=data_loader_test, device=device, epoch=None,set=\"test\")\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def FRCNN_predict(experiment_name,model,dataset_path,batch_size=1,imgsz=416):\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    dataset_train = VOCDataset(dataset_path, image_set=\"train\")\n",
    "    dataset_test = VOCDataset(dataset_path, image_set=\"test\")\n",
    "    class_names = dataset_train.classes\n",
    "    \n",
    "    show_predictions(experiment_name=experiment_name,model=model,dataset=dataset_test,device=device,score_threshold=0.25,class_names=class_names)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    experiment_name=\"prova5\"\n",
    "    model = FRCNN_train(experiment_name=experiment_name,dataset_path=\"dataset\",batch_size=2)\n",
    "    FRCNN_eval(experiment_name=experiment_name,model=model,dataset_path=\"dataset\",batch_size=2)\n",
    "    FRCNN_predict(experiment_name=experiment_name,model=model,dataset_path=\"dataset\",batch_size=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#mettere nel file csv le metriche di ogni epoca âœ…\n",
    "#inserire weight and biases (oppure tensorboard) âœ…\n",
    "#salvare il best.pth del modello âœ…\n",
    "#fare la evaluation sul valid set oltre a quella di train(aggiungi la loss/val su tensorboard), salvare il best.pth in base alla map sul valid set(segna epoca nel file) âœ…\n",
    "#fare evaluation sul test set con il best.pth salvato âœ…\n",
    "#dare le etichette delle classi e le probabilitÃ  nelle predizioni âœ…\n",
    "#fare il resize delle immagini (416x416 di default) âœ…\n",
    "#cambiare il colore della bounding box in base alla classe in maniera randomica âœ…\n",
    "#refactor con divisione in celle, oppure vari file.py\n",
    "#vedere se ci sono fx per metriche aggiuntive\n",
    "#training  \n",
    "#commentare il codice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc136765",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
